# NLP Classification Pipeline Configuration

project:
  name: "nlp-classification"

# MLflow configuration
mlflow:
  # MLflow tracking URI (optional)
  # Examples:
  #   - Local file: "file:./mlruns"
  #   - SQLite: "sqlite:///mlflow.db"
  #   - Remote server: "http://localhost:5000"
  #   - Leave null to use default local ./mlruns directory
  tracking_uri: null

data:
  # Data source
  data_path: "data/**/"  # Path pattern for review files
  test_size: 0.2
  validation_size: 0.1  # Fraction of remaining data after test split
  
  # Random seed for reproducibility
  random_state: 47

preprocessing:
  # Text preprocessing options
  lowercase: true
  remove_punctuation: true
  remove_numbers: true
  remove_stopwords: true
  stemming: false  # Options: false, "porter", "snowball"
  lemmatization: true  # Uses WordNetLemmatizer
  
  # Vectorization
  vectorization_method: "tfidf"  # Options: "tfidf", "count", "hashing"
  max_features: 10000  # Maximum number of features for vectorization
  min_df: 2  # Minimum document frequency
  max_df: 0.95  # Maximum document frequency
  ngram_range: [1, 2]  # Unigrams and bigrams

models:
  # Machine Learning Models
  ml:
    logistic_regression:
      C: 1.0
      penalty: "l2"
      solver: "lbfgs"
      max_iter: 1000
      random_state: 42
    
    naive_bayes_multinomial:
      alpha: 1.0
      fit_prior: true
    
    naive_bayes_bernoulli:
      alpha: 1.0
      fit_prior: true
      binarize: 0.0
    
    naive_bayes_gaussian:
      var_smoothing: 1e-09

evaluation:
  # Metrics to calculate
  metrics: ["accuracy", "precision", "recall", "f1", "roc_auc"]
  
  # Cross-validation settings
  cv_splits: 5
  
  # Classification report
  classification_report: true

paths:
  data_raw: "data/raw/"
  data_processed: "data/processed/"
  models_dir: "results/models/"
  figures_dir: "results/figures/"
  metrics_dir: "results/metrics/"


