# Core dependencies
numpy>=1.21.0
pandas>=1.3.0
scikit-learn>=1.0.0
nltk>=3.6
beautifulsoup4>=4.9.0
lxml>=4.6.0
matplotlib>=3.4.0
pyyaml>=5.4.0
joblib>=1.0.0
mlflow>=2.0.0
tqdm>=4.64.0

# =====================================================
# Deep Learning dependencies (optional)
# =====================================================
# Required for MLP, CNN, LSTM, GRU, Attention, Transformer
# 
# Note: torch should be installed separately based on your
# system configuration (CPU/CUDA). See: https://pytorch.org

# torch>=2.0.0
# pytorch-lightning>=2.0.0  # For LSTM/GRU/Attention models

# For quick installation with CUDA:
#   pip install torch --index-url https://download.pytorch.org/whl/cu118
#   pip install pytorch-lightning

# For CPU-only:
#   pip install torch --index-url https://download.pytorch.org/whl/cpu
#   pip install pytorch-lightning

# =====================================================
# Transformer/LM dependencies (optional)
# =====================================================
# Required for BERT, DistilBERT, RoBERTa fine-tuning
# Uncomment the lines below to enable LM experiments

# transformers>=4.35.0
# datasets>=2.14.0

# For quick installation with CUDA support, run:
#   pip install torch --index-url https://download.pytorch.org/whl/cu118
#   pip install transformers datasets

# For CPU-only installation, run:
#   pip install torch --index-url https://download.pytorch.org/whl/cpu
#   pip install transformers datasets

# =====================================================
# Accelerate - Multi-GPU & Mixed Precision (optional)
# =====================================================
# Recommended for Phase 1 (BERT fine-tuning)
# Handles multi-GPU, FP16/BF16, gradient accumulation

# accelerate>=0.24.0

# For quick installation:
#   pip install accelerate
# For multi-GPU setup:
#   accelerate config

# =====================================================
# Unsloth - Efficient LoRA Fine-tuning (optional)
# =====================================================
# Recommended for Phase 3 (LLM fine-tuning)
# 2-5x faster training with 60% less memory

# unsloth
# trl>=0.7.0  # Required for SFTTrainer

# For quick installation (requires CUDA):
#   pip install unsloth
#   pip install trl
# See: https://github.com/unslothai/unsloth

# =====================================================
# DSpy - Prompt Optimization (optional)
# =====================================================
# Recommended for Phase 2 (systematic prompt engineering)
# Treats prompts as learnable parameters

# dspy-ai>=2.0.0

# For quick installation:
#   pip install dspy-ai

# =====================================================
# LLM Prompting dependencies (optional)
# =====================================================
# Required for zero-shot, few-shot, and chain-of-thought prompting
# Uses LangChain for prompt templates

# langchain>=0.1.0
# langchain-core>=0.1.0
# langchain-huggingface>=0.0.1
# huggingface_hub>=0.20.0

# For quick installation:
#   pip install langchain langchain-core langchain-huggingface huggingface_hub

# Note: You'll need a HuggingFace API token for API-based inference
# Get one at: https://huggingface.co/settings/tokens
# Set it as an environment variable: export HF_TOKEN=your_token_here

# =====================================================
# Installation Guides by Phase
# =====================================================
# 
# Core ML only:
#   pip install -r requirements.txt
#
# Deep Learning (MLP, CNN, LSTM, Transformer):
#   pip install torch --index-url https://download.pytorch.org/whl/cu118
#   pip install pytorch-lightning
#
# BERT Fine-tuning:
#   pip install transformers accelerate datasets
#
# LLM Prompting (Zero/Few-shot, CoT):
#   pip install langchain langchain-core langchain-huggingface huggingface_hub
#   # Optional: DSpy for prompt optimization
#   pip install dspy-ai
#
# LLM Fine-tuning with LoRA (Unsloth):
#   pip install unsloth trl
#
# Everything (Full Installation):
#   pip install torch --index-url https://download.pytorch.org/whl/cu118
#   pip install pytorch-lightning
#   pip install transformers accelerate datasets
#   pip install langchain langchain-core langchain-huggingface huggingface_hub
#   pip install dspy-ai
#   pip install unsloth trl
